{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567ca480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba75a48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9c98e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product_attention(q, K, V):\n",
    "    \"\"\" Dot-Product Attention on one query\n",
    "    Args:\n",
    "        q: a vector with shape [k]\n",
    "        K: a matrix with shape [m, k], means m keys\n",
    "        V: a matrix with shape [m, v], means m values\n",
    "    Returns:\n",
    "        y: a vector with shape [v]\n",
    "    \"\"\"\n",
    "    logits = torch.einsum(\"k, mk->m\", q, K)\n",
    "    weights = F.softmax(logits, dim=0)\n",
    "    return torch.einsum(\"m,mv->v\", weights, V)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55dfb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 512\n",
    "SRC_LEN = D * 2\n",
    "q = torch.randn(D)\n",
    "K = torch.randn(SRC_LEN, D)\n",
    "V = torch.randn(SRC_LEN, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee7a2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dot_product_attention(q, K, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c601fe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y.shape == torch.Size((D,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ba752c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f339b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multihead_attention(x, M, P_q, P_k, P_v, P_o):\n",
    "    \"\"\"Multi-head Attention on one query\n",
    "    Args :\n",
    "        x: a vector with shape [d]\n",
    "        M: a matrix with shape [m, d], m is source sequence length\n",
    "        P_q: a tensor with shape [h, d, k], the projection tensor for query\n",
    "        P_k: a tensor with shape [h, d, k], the \n",
    "        P_v: a tensor with shape [h, d, v]\n",
    "        P_o: a tensor with shape [h, d, v]\n",
    "        Returns :\n",
    "        y : a vector with shape [d]\n",
    "    \"\"\"\n",
    "    q = torch.einsum(\"d, hdk->hk\", x, P_q)\n",
    "    K = torch.einsum(\"md, hdk->hmk\", M, P_k)\n",
    "    V = torch.einsum(\"md, hdv->hmv\", M, P_v)\n",
    "    logits = torch.einsum(\"hk, hmk->hm\", q, K)\n",
    "    weights = torch.softmax(logits, dim=-1)\n",
    "    o = torch.einsum(\"hm,hmv->hv\", weights, V)\n",
    "    y = torch.einsum(\"hv, hdv->d\", o, P_o)\n",
    "    return y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfde341",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 512\n",
    "H = 16\n",
    "K = V = D // H\n",
    "SRC_LEN = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190dd3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((D,))\n",
    "M = torch.randn((SRC_LEN, D))\n",
    "P_q = torch.randn((H, D, K))\n",
    "P_k = torch.randn((H, D, K))\n",
    "P_v = torch.randn((H, D, V))\n",
    "P_o = torch.randn((H, D, V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52997ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = multihead_attention(x, M, P_q, P_k, P_v, P_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145de7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y.shape == torch.Size((D,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dad61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multihead_attention_batched(X, M, mask, P_q, P_k, P_v, P_o):\n",
    "    \"\"\" Multiâˆ’head Attention.\n",
    "        Args :\n",
    "            X: a tensor with shape [b, n, d]\n",
    "            M: a tensor with shape [b, m, d]\n",
    "            mask : a tensor with shape [b, h, n, m]\n",
    "            P_q: a tensor with shape [h, d, k]\n",
    "            P_k: a tensor with shape [h, d, k]\n",
    "            P_v: a tensor with shape [h, d, v]\n",
    "            P_o: a tensor with shape [h, d, v]\n",
    "        Returns :\n",
    "            Y: a tensor with shape [b, n, d]\n",
    "    \"\"\"\n",
    "    Q = torch.einsum(\"bnd, hdk->bhnk\", X, P_q)\n",
    "    K = torch.einsum(\"bmd, hdk->bhmk\", M, P_k)\n",
    "    V = torch.einsum(\"bmd, hdv->bhmv\", M, P_v)\n",
    "    logits = torch.einsum(\"bhnk,bhmk->bhnm\", Q, K)\n",
    "    weights = F.softmax(logits + mask, dim=-1)\n",
    "    O = torch.einsum(\"bhnm,bhmv->bhnv\", weights, V)\n",
    "    Y = torch.einsum(\"bhnv,hdv->bnd\", O, P_o)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf52b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 32\n",
    "SRC_LEN = 256\n",
    "TGT_LEN = 128\n",
    "D = 512\n",
    "H = 16\n",
    "K = V = D // H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6604917",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((B, TGT_LEN, D))\n",
    "M = torch.randn((B, SRC_LEN, D))\n",
    "MASK = torch.randn((B, H, TGT_LEN, SRC_LEN))\n",
    "P_q = torch.randn((H, D, K))\n",
    "P_k = torch.randn((H, D, K))\n",
    "P_v = torch.randn((H, D, V))\n",
    "P_o = torch.randn((H, D, V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511697ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = multihead_attention_batched(x, M, MASK, P_q, P_k, P_v, P_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1be47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y.shape == torch.Size((B, TGT_LEN, D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c905a4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
