{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "567ca480",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db334177",
   "metadata": {},
   "source": [
    "# 1. Bert main logic\n",
    "## 1.1 Bert tokens\n",
    "```python\n",
    "  tensor([[101, 1188, 1110, 1126, 7758, 1859, 102]])\n",
    "```\n",
    "  \\[CLS\\] --> 101 and \\[SEP\\] --> 102\n",
    "  \n",
    "## 1.2 Embedding\n",
    "[code](https://github.com/huggingface/transformers/blob/3658488ff77ff8d45101293e749263acf437f4d5/src/transformers/models/bert/modeling_bert.py#L180)\n",
    "\n",
    "### Logic\n",
    "Adding token embedding, abs position embedding and token type embedding\n",
    "\n",
    "### Input\n",
    "B X S where B is batch size and S is sequence length\n",
    "\n",
    "#### Output\n",
    "B X S X D, where D is dimension\n",
    "\n",
    "\n",
    "\n",
    "## 1.3 Encoder\n",
    "[code](https://github.com/huggingface/transformers/blob/3658488ff77ff8d45101293e749263acf437f4d5/src/transformers/models/bert/modeling_bert.py#LL561C4-L561C4)\n",
    "\n",
    "### Logic\n",
    "\n",
    "It has layers, like 12 layers\n",
    "Hidden states corresponding to layer_outputs\\[0\\]\n",
    "If we want all hidden state, then put them in a tuple\n",
    "Attentions corresponding to layer_outputs\\[1\\]\n",
    "\n",
    "### Input\n",
    "1. Emedding output\n",
    "2. attention_mask\n",
    "3. head_mask\n",
    "4. previous encoder_hidden_states\n",
    "5. encoder_attention_mask\n",
    "6. previous output_attentions\n",
    "7. previous output_hidden_states\n",
    "\n",
    "\n",
    "## 1.4 Model output\n",
    "sequence_output, pooled_output, (hiddent_states), (attentions), (cross_attentions)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cc3b7a",
   "metadata": {},
   "source": [
    "## BertEncoder\n",
    "\n",
    "### Input\n",
    "1. hiddent_states\n",
    "2. attention_mask\n",
    "3. head_mask\n",
    "4. previous encoder_hidden_states\n",
    "5. encoder_attention_mask\n",
    "6. previous output_attentions\n",
    "7. prevous output_hidden_states\n",
    "\n",
    "\n",
    "### output\n",
    "hidden_states, next_decoder_cache(keys), (all_hidden_states), (all_self_attentions), (all_cross_attentions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15168d65",
   "metadata": {},
   "source": [
    "Bert Self Attention logic\n",
    "\n",
    "Note if we have encode_hidden_states, then it is cross attention\n",
    "\n",
    "\n",
    "```python\n",
    "def forward(self, hidden_states, attention_mask=None, head_mask=None,\n",
    "    \t\tencoder_hidden_states=None, encoder_attention_mask=None,\n",
    "    \t\toutput_attentions=False):\n",
    "    # step 1: mapping Query/Key/Value to sub-space\n",
    "    # step 1.1: query mapping\n",
    "    mixed_query_layer = self.query(hidden_states) # B x S x (H*d)\n",
    "    \n",
    "    # If this is instantiated as a cross-attention module, the keys\n",
    "    # and values come from an encoder; the attention mask needs to be\n",
    "    # such that the encoder's padding tokens are not attended to.\n",
    "    \n",
    "    # step 1.2: key/value mapping\n",
    "    if encoder_hidden_states is not None:\n",
    "        mixed_key_layer = self.key(encoder_hidden_states) # B x S x (H*d)\n",
    "        mixed_value_layer = self.value(encoder_hidden_states) \n",
    "        attention_mask = encoder_attention_mask \n",
    "    else:\n",
    "        mixed_key_layer = self.key(hidden_states) # B x S x (H*d)\n",
    "        mixed_value_layer = self.value(hidden_states)\n",
    "\n",
    "    query_layer = self.transpose_for_scores(mixed_query_layer) # B x H x S x d\n",
    "    key_layer = self.transpose_for_scores(mixed_key_layer) # B x H x S x d\n",
    "    value_layer = self.transpose_for_scores(mixed_value_layer) # B x H x S x d\n",
    "\n",
    "    # step 2: compute attention scores\n",
    "    \n",
    "    # step 2.1: raw attention scores\n",
    "    # B x H x S x d   B x H x d x S -> B x H x S x S\n",
    "    # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
    "    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "    attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "    \n",
    "    # step 2.2: mask if necessary\n",
    "    if attention_mask is not None:\n",
    "       # Apply the attention mask, B x H x S x S\n",
    "    \tattention_scores = attention_scores + attention_mask\n",
    "\n",
    "    # step 2.3: Normalize the attention scores to probabilities, B x H x S x S\n",
    "    attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
    "\n",
    "    # This is actually dropping out entire tokens to attend to, which might\n",
    "    # seem a bit unusual, but is taken from the original Transformer paper.\n",
    "    attention_probs = self.dropout(attention_probs)\n",
    "\n",
    "    # Mask heads if we want to\n",
    "    if head_mask is not None:\n",
    "        attention_probs = attention_probs * head_mask\n",
    "\t# B x H x S x S   B x H x S x d ->  B x H x S x d\n",
    "    \n",
    "    # step 4: aggregate values by attention probs to form context encodings\n",
    "    context_layer = torch.matmul(attention_probs, value_layer)\n",
    "\t# B x S x H x d\n",
    "    context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "    # B x S x D\n",
    "    new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
    "    # B x S x D，相当于是多头concat操作\n",
    "    context_layer = context_layer.view(*new_context_layer_shape)\n",
    "\n",
    "    outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
    "    return outputs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4f06bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\local\\Anaconda3\\envs\\gpu2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)okenizer_config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 29.0/29.0 [00:00<?, ?B/s]\n",
      "Downloading (…)lve/main/config.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 570/570 [00:00<?, ?B/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 213k/213k [00:00<00:00, 1.55MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 436k/436k [00:00<00:00, 3.33MB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 570/570 [00:00<00:00, 570kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading pytorch_model.bin: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 436M/436M [00:19<00:00, 22.6MB/s]\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "MODEL_NAME = \"bert-base-cased\"\n",
    "\n",
    "# step 1: 先获取tokenizer, BertTokenizer, \n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, cache_dir='.cache/token') \n",
    "# step 2: 获取预训练好的模型, BertModel\n",
    "model = AutoModel.from_pretrained(MODEL_NAME, cache_dir='.cache/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a685eee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93f9ce82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertEmbeddings(\n",
       "  (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "  (position_embeddings): Embedding(512, 768)\n",
       "  (token_type_embeddings): Embedding(2, 768)\n",
       "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81650d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47db9dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"A dog chases a fox\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "698c8c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,   138,  3676,  9839,  1116,   170, 17594,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c284dfde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'A', 'dog', 'chase', '##s', 'a', 'fox', '[SEP]']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(inputs['input_ids'].numpy().squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38311688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "inputs = inputs.to(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae021665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,   138,  3676,  9839,  1116,   170, 17594,   102]],\n",
       "       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fcc5c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3478bfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = outputs.to_tuple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8627954d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = []\n",
    "for o in outputs:\n",
    "    r.append(o.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c32dbf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 768])\n",
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "for o in r:\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acc73e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4496,  0.0977, -0.2074,  ...,  0.0578,  0.0406, -0.0951],\n",
       "         [-0.2927,  0.2770,  0.6649,  ...,  0.9219,  0.5406,  0.5588],\n",
       "         [-0.0497, -1.5883,  0.2633,  ..., -0.2919, -1.3644, -1.3365],\n",
       "         ...,\n",
       "         [-0.5258,  1.0663, -0.4180,  ...,  0.0359,  0.8914,  0.3006],\n",
       "         [ 0.0403, -1.1036,  0.2559,  ...,  1.0463,  0.7956,  0.4520],\n",
       "         [-0.0460,  0.0234,  0.2679,  ...,  0.4408, -0.5575,  0.4839]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = model.embeddings(inputs['input_ids'], inputs['token_type_ids'])\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "066f26fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model.encoder(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "20515608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPastAndCrossAttentions(last_hidden_state=tensor([[[-0.0351, -0.0827, -0.0797,  ..., -0.0248,  0.2941, -0.0887],\n",
       "         [-0.2311, -0.4525,  0.3582,  ...,  0.7687,  0.6660,  0.1785],\n",
       "         [ 0.4097, -0.2633, -0.2330,  ...,  0.0906, -0.2991, -0.0815],\n",
       "         ...,\n",
       "         [-0.1230, -0.2945, -0.4637,  ...,  0.1498,  0.1764,  0.1671],\n",
       "         [ 0.2305, -0.5759, -0.0623,  ..., -0.3432, -0.0735,  0.1954],\n",
       "         [ 0.4334,  0.2996, -0.5675,  ..., -0.2275,  0.1948, -0.1666]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a224a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 o.detach()                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'BaseModelOutputWithPastAndCrossAttentions'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'detach'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 o.detach()                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mAttributeError: \u001b[0m\u001b[32m'BaseModelOutputWithPastAndCrossAttentions'\u001b[0m object has no attribute \u001b[32m'detach'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "o.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ae0bc0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8ea96e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'Nice', 'to', '[MASK]', 'you', '[SEP]']\n",
      "[('meet', tensor(0.9712, device='cuda:0')), ('see', tensor(0.0267, device='cuda:0')), ('meeting', tensor(0.0010, device='cuda:0')), ('have', tensor(0.0003, device='cuda:0')), ('met', tensor(0.0002, device='cuda:0')), ('know', tensor(0.0001, device='cuda:0')), ('join', tensor(7.0004e-05, device='cuda:0')), ('find', tensor(5.8323e-05, device='cuda:0')), ('Meet', tensor(2.7171e-05, device='cuda:0')), ('tell', tensor(2.4689e-05, device='cuda:0'))]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForMaskedLM\n",
    "\n",
    "text = \"Nice to [MASK] you\" # target token using [MASK] to mask\n",
    "\n",
    "# step 1: obtain pretrained Bert Model using MLM Loss\n",
    "maskedLM_model = BertForMaskedLM.from_pretrained(MODEL_NAME, cache_dir='.cache/model')\n",
    "maskedLM_model = maskedLM_model.to(device)\n",
    "\n",
    "maskedLM_model.eval() # close dropout\n",
    "\n",
    "# step 2: tokenize\n",
    "token_info = tokenizer.encode_plus(text, return_tensors='pt')\n",
    "tokens = tokenizer.convert_ids_to_tokens(token_info['input_ids'].squeeze().numpy())\n",
    "print(tokens) # ['[CLS]', 'Nice', 'to', '[MASK]', 'you', '[SEP]']\n",
    "\n",
    "# step 3: forward to obtain prediction scores\n",
    "token_info = token_info.to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = maskedLM_model(**token_info)\n",
    "    predictions = outputs[0] # shape, B x S x V, [1, 6, 28996]\n",
    "    \n",
    "# step 4: top-k predicted tokens\n",
    "masked_index = tokens.index('[MASK]') # 3\n",
    "k = 10\n",
    "probs, indices = torch.topk(torch.softmax(predictions[0, masked_index], -1), k)\n",
    "\n",
    "predicted_tokens = tokenizer.convert_ids_to_tokens(indices.tolist())\n",
    "print(list(zip(predicted_tokens, probs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d417e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
